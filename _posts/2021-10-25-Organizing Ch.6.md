# 6장 머신러닝의 작업흐름

## 이 장은 다음 세가지에 대해 다룹니다.

1. 머신러닝 문제를 프레임화 하기
2. 작업모델을 개발하기
3. 프로덕션에서 모델을 배포하고 유지 관리하는 단계

우리의 이전 예들은 우리가 이미 시작할 레이블링된 데이터 세트를 가지고 있다고 가정했다.

# 6.1 무엇을 하는지 확실히 알아야합니다.

당신은 당신이 무얼 하고 있는지에 대한 맥락에 대해 아주 깊은 이해도가 없다면 좋은 모델을 만들 수 없습니다. 왜 당신의 고객은 이 특정한 문제를 해결하려고 할까요? 고객이 솔루션에서 어떤 가치를 창출할 수 있을까요? 모델을 어떻게 사용하고, 고객의 비지니스 프로세스에 어떻게 맞출 수 있을까요? 어떤 종류의 데이터가 사용가능한지 또는 수집될 수 있을까요? 어떤 종류의 머신러닝이 비지니스 문제점을 발견할 수 있을까요?

## 6.1.1 문제의 틀을 잡으세요.

머신러닝 문제의 틀을 잡는것은 보통 관계자들과의 충분하고 섬세한 의논이 이루어져야 합니다. 여기 마음을 졸일만한 질문들을 몇개 던져 보겠습니다.

* 무엇에 당신의 데이터를 입력하시겠습니까? 무엇을 예측하려고 노력하십니까? 당신은 사용가능한 훈련데이터가 있어야만 예측을 할 수 있습니다. : 예를들어 당신이 두개의 영화리뷰를 가지고 있다고 칠 때 당신은 영화 리뷰가 비평인지 호평인지 분류할 수 있습니다. 이와 같이, 이 단계에서는 데이터의 가용성이 일반적으롤 제한적 요인입니다. 대부분의 경우, 당신은 스스로 새로운 데이터셋을 모으고 주석을 다는 것에 의지해야만 할 것 입니다.(이건 다음장에서 다루겠습니다.)

* 어떤 머신러닝 기법을 다루어보셨나요? 이진분류? 다중분류? 스칼라 회귀? 소프트벡터 회귀? 다중 라벨 분류? 이미지 분석? 랭킹 시스템? 다른 것들로는 군집화, 일반화, 또는 강화학습등을 다루어보셨나요? 경우에 따라서는 머신러닝 기법이 당신의 데이터를 가장 잘 다루게 하는 기법이 아닐 수 있습니다. 이러한 경우 평범한 구식의 통계분석이 더 잘 다루게 할 수 있습니다.
  + 이미지 검색 엔진 프로젝트는 다중분류, 다중라벨분류에 속합니다.
  + 스팸 메일 분류하기 프로젝트는 이진분류에 해당합니다. 만약 당신이 공격적인 단어를 세팅한다면 별개의 일로 쳐서 세가지 분류작업으로 해당합니다.
  + 음악 추천 엔진은 딥러닝이 아닌 매트릭스 인수분해를 통해 더 잘 다루어진다고 판명났다.(필터링이 있다는 존재하에)
  + 신용카드 사기 분류 프로젝트는 이진 분류에 속합니다.
  + 클릭률 예측 프로젝트는 스칼라 회귀방식입니다.
  + 변칙 쿠키 분류하기는 이진 분류 방식이지만, 원시 이미지에서 쿠키를 올바르게 잘라내기 위해 첫 번째 단계로 객체 탐지 모델이 필요합니다. "이상 탐지"로 알려진 머신러닝 기법은 변칙 쿠키 분류하는데 있어서 좋지 않은 방법이니 유의하세요.
  + 위성사진으로 본 고고학 유적지를 찾아내는 것에 대한 프로젝트는 랭킹 시스템과 유사합니다: 당신은 알려져있는 고고학 유적지와 가장 흡사한 이미지들을 회수할 필요가 있습니다.
* 기존 솔루션은 어떠한 모습입니까? 아마도 여러분의 고객은 이미 스팸 메일 분류나 신용 카드 사기 분류를 할 수 있는 수작업 알고리즘을 하고 있습니다. 아마도 사람은 현재 쿠키 공장에서 컨베이어 벨트를 직접 모니터링하고 불량 쿠키들을 수동으로 제거하거나 특정 아티스트를 좋아하는 사용자들에게 보낼 추천곡의 노래 재생 목록을 만드는 것 처럼 대부분의 일을 수동으로 처리하고 있습니다. 당신은 어떤 시스템이 이미 구축되어 있는지, 그리고 어떻게 작동하는지 이해해야만 해요.
* 처리해야 할 특별한 제약이 있습니까? 예를 들어, 스팸 탐지 시스템을 구축하는 앱이 철저하게 종단 간 암호화되어 있기 때문에 스팸 탐지 모델은 최종 사용자의 전화기에서 작동해야 하며 외부 데이터 세트에 대해 교육을 받아야 합니다. 아마도 쿠키 필터링 모델은 원격 서버보다는 공장에서 임베디드 장치에서 실행되어야 하는 지연 시간 제약 조건을 가지고 있을 것입니다. 당신은 당신의 모델이 들어맞을 전체 맥락을 이해해야 한다.
이는 검증되거나 무효화되기를 바라는 가설에 불과합니다. 모든 문제가 머신러닝으로 해결할 수 있는 것은 아닙니다. 왜냐하면 당신이 X라는 입력값의 예제를 취합하였다 라는 말이 타겟값인 Y가 X에 Y를 예측하기에 충분한 정보가 포함되어 있다는 것을 의미하지는 않습니다. 예를 들어 당신이 주식에서 최근 가격 이력을 고려했다고 해서 주식시장에서 주식의 움직임을 예측하려고 한다면, 성공할 가능성이 매우 낮습니다. 왜냐면 가격 이력은 예측 정보를 많이 포함하지 않기 때문입니다.





## 6.1.2 데이터 셋을 모으세요.


작업의 특성을 이해하고 입력과 대상이 무엇인지 알게 되면 대부분의 머신러닝 프로젝트에서 가장 힘들고 시간이 많이 걸리며 비용이 많이 드는 부분인 데이터 수집이 필요한 시점입니다.

1. 사진 검색 엔진 프로젝트 : 먼저 분류할 레이블 세트를 선택해야 합니다. 즉, 10,000개의 일반적인 이미지 범주에 따라 결정됩니다. 그런 다음 이 세트의 레이블로 사용자가 업로드한 과거 이미지 수십만 개에 수동으로 태그를 지정해야 합니다.

2. 채팅 앱 스팸 탐지 프로젝트 : 사용자 채팅이 서로 암호화 되어있어서 이것을 모델 훈련에 사용할 수 없습니다. 그래서 수만 개의 공개 소셜 미디어 게시물로 구성된 별도의 데이터 세트에 접근하여 스팸, 불쾌감 또는 허용 가능한 태그를 수동으로 지정해야 합니다.

3. 음악 추천 엔진과 클릭률 예측 프로젝트 : 음악 추천 엔진과 클릭률 예측 프로젝트는 비슷한데 전자는 사용자들의 "좋아요"를 이용하면 되고 후자는 과거 광고에 대한 클릭률의 기록을 이용하면 됩니다.

4. 쿠킹 플래깅 모델 : 컨베이어 벨트 위에 카메라를 설치하여 수만 개의 이미지를 수집한 다음 사람이 직접 수동으로 이 이미지에 레이블을 지정해야 합니다.

5. 위성사진 프로젝트 : 고고학 팀이 기존 관심 장소의 데이터베이스를 수집해야 하며, 각 사이트에 대해 다른 기상 조건에서 찍은 기존 위성 사진을 찾아야 합니다. 좋은 모델을 얻으려면 수천 개의 다른 사이트가 필요합니다.

5장에서 모델의 일반화 기능은 거의 전적으로 모델이 학습한 데이터의 속성(데이터 포인트 수, 레이블의 안정성, 기능 품질)에서 비롯된다는 것을 배웠습니다.

좋은 데이터 세트는 케어와 투자 가치가 있는 자산입니다. 어느 정도냐면 프로젝트에 50시간을 쓴다고 가정할 때 증분 모델링 개선 사항을 검색하는 것보다 더 많은 데이터를 수집하는 것이 더 효과적일 수 있습니다.

알고리즘보다 데이터가 더 중요하다는 지적은 구글 연구원들이 2009년 발표한 "데이터의 불합리한 효과" 에서 가장 잘 알려져 있습니다. 이는 딥러닝이 유행하기 전이지만, 놀랍게도 딥러닝의 부상은 데이터의 중요성을 더 키웠습니다.

지도 학습을 수행하는 경우 입력(예: 이미지)을 수집한 후 해당 입력(예: 이미지 태그)에 대한 주석이 필요합니다. 즉, 모델이 예측할 수 있도록 만드는 목표입니다.

때로는 음악 추천 작업이나 클릭률 예측 작업의 경우처럼 주석을 자동으로 검색할 수 있습니다. 하지만 대부분은 데이터에 주석을 직접 달아야 합니다. 이것은 노동력이 많이 드는 과정입니다.

#### 데이터 주석 인프라에 대한 투자

데이터 주석 처리에 따라 목표값의 품질이 결정되고, 이는 다시 모델의 품질을 결정합니다. 따라서 사용할 수 있는 요소들을 신중하게 골라야 합니다.

- 데이터에 주석을 직접 달아야 할까요?
- 라벨을 수집하기 위해 기계 투르크인과 같은 크라우드소싱 플랫폼을 사용해야 할까요?
- 데이터 라벨링 전문 회사 서비스를 이용해야 할까요?

아웃소싱은 잠재적으로 시간과 비용을 절약할 수 있지만 통제력을 잃게 만들 수 있습니다. 기계 투르크인과 같은 것을 사용하는 것은 저렴하고 잘 확장될 수 있지만, 여러분의 주석들은 꽤 어지럽게 끝날지도 모릅니다.



최고의 방법을 선택하기 위해서는 작업 중인 "제약 조건"을 고려해보세요.

- 데이터 라벨 작성자가 그 주제의 전문가여야 합니까, 아니면 데이터에 주석을 달 수 있는 사람이 있습니까? 고양이vs개 이미지 분류 문제의 라벨은 누구나 선택할 수 있지만, 개 품종 분류 작업의 라벨은 전문 지식이 필요합니다. 또는 뼈 골절의 CT 스캔에 주석을 달려면 의학 학위가 필요합니다.

- 데이터에 주석을 달아야 하는 전문 지식이 있다면, 그 전문지식을 배울 수 있을까요? 그렇지 않다면, 관련 전문가와 어떻게 접촉할 수 있을까요?

- 전문가들이 어떻게 주석을 달 수 있는지 알고 계십니까? 그렇지 않으면 데이터 세트를 블랙박스로 취급해야 하며 수동 기능 엔지니어링을 수행할 수 없습니다. 이는 중요하지는 않지만 제한적일 수 있습니다.

- 데이터에 레이블을 붙이기로 결정한 경우 주석을 기록하는 데 사용할 소프트웨어를 생각해보세요. 당신이 직접 그 소프트웨어를 개발해야 할 수도 있습니다. 생산적인 데이터 주석 소프트웨어는 많은 시간을 절약할 수 있으므로 프로젝트 초기에 투자할 가치가 있습니다.

#### 대표적이지 않은 데이터를 주의하세요

머신러닝 모델은 이전에 본 것과 유사한 입력만 이해할 수 있습니다. 따라서 교육에 사용되는 데이터가 생산 데이터를 대표해야 합니다. 이 문제는 모든 데이터 수집의 기반이 작동해야 합니다.

사용자가 음식 이름을 알기 위해 사진을 찍을 수 있는 앱을 개발 중이라고 가정해봅시다.

식도락가들에게 인기 있는 이미지 공유 소셜 네트워크의 사진을 사용하여 모델을 훈련시킵니다. 배포 시간이 다가오면 분노한 사용자의 피드백이 쏟아지기 시작합니다. 즉, 앱이 10점 만점에 8번 오답합니다. 어떤 일이 있을까요? 테스트 세트의 정확도는 90%를 훨씬 넘었습니다! 사용자가 업로드한 데이터를 빠르게 살펴보면 무작위의 스마트폰으로 찍은 랜덤 음식점의 모바일 사진 업로드가 모델을 교육한 전문가 품질의 밝은 식탐을 돋우는 사진과는 전혀 다르다는 것을 알 수 있습니다. 교육 데이터는 프로덕션 데이터를 대표하지 못했습니다. 그건 굉장히 잘못 된겁니다. 머신러닝의 지옥에 온 걸 환영해요.

가능하면 모델을 사용할 환경에서 직접 데이터를 수집하십시오. 영화 감상 분류 모델은 옐프 레스토랑 리뷰나 트위터 상태 업데이트가 아닌 새로운 IMDB 리뷰에 사용되어야 합니다. 트윗의 감성을 평가하려면 프로덕션에서 예상하는 사용자 집합과 유사한 사용자로부터 실제 트윗을 수집하고 주석을 다는 것부터 시작하십시오. 프로덕션 데이터에 대한 교육을 실시할 수 없는 경우에는 교육 데이터와 프로덕션 데이터가 어떻게 다른지 완전히 이해하고 이러한 차이를 적극적으로 수정해야 합니다.

당신이 알아야 할 관련 현상은 개념 드리프트입니다. 실제로 발생하는 거의 모든 문제, 특히 사용자 생성 데이터를 다루는 문제에서 개념의 표류를 경험할 수 있습니다. 

개념 드리프트는 시간이 지남에 따라 생산 데이터의 속성이 변경되어 모형 정확도가 점차 저하될 때 발생합니다. 2013년에 교육받은 음악 추천 엔진은 오늘날 그다지 효과적이지 않을 수 있습니다. 마찬가지로, 작업한 IMDB 데이터 집합도 2011년에 수집되었으며, 이 데이터 집합으로 훈련된 모델은 시간이 지남에 따라 어휘, 표현 및 영화 장르가 발전함에 따라 2012년의 리뷰에 비해 2020년의 리뷰에서 제대로 수행되지 못할 수 있습니다. 개념의 표류는 신용 카드 사기 탐지와 같은 적대적인 맥락에서 특히 심하며, 사기 패턴은 실질적으로 매일 변화합니다. 빠른 개념 드리프트를 처리하려면 지속적인 데이터 수집, 주석 및 모델 재교육이 필요합니다.

머신러닝은 교육 데이터에 있는 패턴을 암기하는 데만 사용될 수 있습니다. 전에 본 것만 알아볼 수 있어요. 과거 데이터에 대해 훈련된 머신러닝을 사용하여 미래를 예측하는 것은 미래가 과거와 같이 행동할 것이라는 가정을 하는 것입니다. 그건 잘못된겁니다.

## 6.1.3 데이터들을 이해하세요.

데이터 세트를 블랙박스로 취급하는 것은 매우 잘못된 관행입니다. 모델을 교육하기 전에 데이터를 탐색하고 시각화하여 예측 가능한 요소에 대한 통찰력을 얻고(기능 엔지니어링에 정보를 제공) 잠재적인 문제를 선별해야 합니다.

- 데이터에 이미지 또는 자연어 텍스트가 포함된 경우 몇 가지 샘플(및 해당 레이블)을 직접 살펴보세요.
- 데이터에 숫자 형상이 포함되어 있는 경우 형상 값의 히스토그램을 그려서 사용된 값의 범위와 다른 값의 빈도를 파악하는 것이 좋습니다.
- 데이터에 위치 정보가 포함되어 있으면 지도에 표시합니다. 뚜렷한 패턴이 있나요?
- 일부 샘플에 일부 기능의 누락 데이터가 있습니까? 그렇다면 데이터를 준비할 때 이 문제를 해결해야 합니다(다음 섹션에서 이 방법을 설명합니다)
- 분류 문제인 경우 데이터에 있는 각 클래스의 인스턴스 수를 인쇄합니다. 클래스가 대략적으로 동등하게 표현됩니까? 그렇지 않다면 이 불균형을 고려해야 합니다.
- 타겟 누수 여부: 데이터에 프로덕션에서 사용할 수 없는 대상에 대한 정보를 제공하는 피쳐가 있는지 확인합니다. 미래에 암으로 치료받을지 여부를 예측하기 위해 의료기록에 대한 모델을 교육하고 있는데, 기록에 "이 사람이 암 진단을 받았다"는 특징이 포함되어 있다면, 여러분의 목표물이 인위적으로 여러분의 데이터에 유출시키고 있는 것입니다. 데이터의 모든 기능이 운영 환경에서도 동일한 형태로 제공되는지 항상 자문해 보십시오.

## 6.1.4 성공의 척도를 고르세요.

무언가를 통제하기 위해서는 그것을 관찰할 수 있어야 합니다. 프로젝트에서 성공을 거두려면 먼저 성공의 의미, 즉 정확성을 정의해야 합니다. 정확성과 기억력요? 고객 유지율이요? 성공을 위한 지표는 프로젝트 전반에 걸쳐 수행할 모든 기술적 선택을 안내합니다. 고객의 비즈니스 성공과 같은 상위 수준의 목표와 직접 연계되어야 합니다.

모든 클래스가 동일한 확률의 균형 분류 문제의 경우, 수신기 작동 특성 곡선(ROC AUC) 아래의 정확도와 영역이 일반적인 지표입니다. 클래스 불균형 문제, 순위 지정 문제 또는 다중 레이블 분류의 경우 정밀도 및 호출뿐만 아니라 가중 정확도 또는 ROC AUC를 사용할 수 있습니다. 또한 성공을 측정하기 위해 자신만의 사용자 지정 메트릭을 정의해야 하는 경우도 흔합니다. 머신러닝 성공 지표의 다양성과 이러한 지표가 서로 다른 문제 영역과 어떤 관련이 있는지 파악하려면 캐글(kaggle.com)에서 데이터 과학 대회를 찾아보면 도움이 됩니다. 다양한 문제와 평가 지표가 표시됩니다.

# 6.2 모델을 개발하세요.

진행 상황을 어떻게 측정할 것인지 알고 나면 모델 개발을 시작할 수 있습니다. 대부분의 튜토리얼 및 연구 프로젝트는 이 단계가 유일한 단계라고 가정합니다. 즉, 이미 수행된 것으로 간주되는 문제 정의 및 데이터 집합은 건너뛰고, 다른 사용자가 처리하는 것으로 간주되는 모델 배치 및 유지보수는 건너뜁니다. 사실 모델 개발은 기계학습 워크플로우에서 한 단계일 뿐이고, 저에게 물어보면 가장 어려운 것은 아닙니다. 머신러닝에서 가장 어려운 것은 골격 문제와 데이터 수집, 주석 달기, 청소입니다. 그러니 힘내세요, 다음에 오는 것은 비교가 쉬울 거예요!

## 6.2.1 데이터를 준비하세요.


앞서 학습한 바와 같이 딥러닝 모델은 일반적으로 원시 데이터를 수집하지 않습니다. 데이터 전처리는 당면한 원시 데이터를 신경망에 더 잘 적응하도록 만드는 것을 목표로 합니다. 여기에는 벡터화, 정규화 또는 누락데이터 처리가 포함됩니다. 많은 사전 처리 기술은 도메인마다 다릅니다(예: 텍스트 데이터 또는 이미지 데이터). 실제 예제에서 이러한 기술을 접할 때 다음 장에서 다루겠습니다. 지금은 모든 데이터 도메인에 공통적으로 적용되는 기본 사항에 대해 살펴보겠습니다.

### 벡터화

신경망의 모든 입력과 대상은 일반적으로 부동소수점 데이터의 텐서(또는 특정한 경우 정수나 문자열의 텐서)여야 합니다. 사운드, 이미지, 텍스트 등 처리해야 할 데이터가 무엇이든 먼저 텐서로 전환해야 하며, 이 단계를 데이터 벡터화라고 합니다. 예를 들어, 4장의 이전 두 텍스트 분류 예에서는 정수 목록(단어 시퀀스를 나타냄)으로 표현된 텍스트에서 시작하여 원핫 인코딩을 사용하여 float32 데이터의 텐서로 변환했습니다. 숫자를 분류하고 집값을 예측하는 예에서는 이미 데이터가 벡터화된 형태로 들어왔기 때문에 이 단계를 건너뛸 수 있었습니다.

### 정규화

2장의 MNIST 숫자 분류 예제에서는 0-255 범위의 정수로 인코딩된 영상 데이터에서 시작하여 그레이스케일 값을 인코딩했습니다. 이 데이터를 네트워크에 입력하기 전에 부동소수점 값이 0-1 범위에 오르게 하려면 먼저 부동소수점 값을 float32로 캐스팅하고 255로 나누어야 합니다. 마찬가지로 주택 가격을 예측할 때 부동소수점 값이 작고 정수 값이 상당히 큰 등 다양한 범위의 특성에서 시작했습니다. 이 데이터를 네트워크에 입력하기 전에 표준 편차가 1이고 평균이 0이 되도록 각 피쳐를 독립적으로 정규화해야 합니다.

일반적으로 상대적으로 큰 값(예: 네트워크의 초기 가중치보다 훨씬 큰 여러 자리 정수)을 사용하는 신경망 데이터나 이기종 데이터(예: 한 기능이 0-1이고 다른 기능이 100-200인 데이터)에 입력하는 것은 안전하지 않습니다. 이렇게 하면 대규모 그라데이션 업데이트가 트리거되어 네트워크가 수렴되지 않을 수 있습니다. 네트워크에서 보다 쉽게 학습하려면 데이터에 다음과 같은 특성이 있어야 합니다.

- 작은 값 사용하기 - 일반적으로 대부분의 값은 0-1 범위여야 합니다.
- 균일성 - 즉, 모든 피쳐가 거의 동일한 범위의 값을 가져야 합니다.

또한 다음과 같은 엄격한 정규화 방법이 일반적이며 항상 필요한 것은 아니지만 도움이 될 수 있습니다(예: 숫자 분류 예제에서 이 작업을 수행하지는 않았습니다).

- 평균이 0이 되도록 각 피쳐를 독립적으로 정규화합니다. x = x.mean(axis=0)
- 표준 편차가 1이 되도록 각 피쳐를 독립적으로 정규화합니다. x /= x.std(axis=0)

### 누락데이터 처리하기

때때로 데이터에 누락 데이터가 있을 수 있습니다. 예를 들어, 집값의 예에서 첫 번째 특징(데이터의 지수 0 열)은 1인당 범죄율입니다. 만약 이 기능이 모든 샘플에서 사용할 수 없다면요? 그러면 교육 또는 검정 데이터에 누락데이터가 있게 됩니다.

기능을 완전히 없앨 수 있지만 반드시 없앨 필요는 없습니다.

- 피쳐가 범주형인 경우 "값이 누락되었습니다"를 의미하는 새 범주를 작성하는 것이 안전합니다. 이 모델은 대상과 관련하여 이것이 의미하는 바를 자동으로 학습합니다.
- 형상이 숫자인 경우 형상에 의해 형성된 잠재 공간에 불연속성이 생성되어 해당 형상에 대해 훈련된 모델이 일반화하기가 더 어려울 수 있으므로 "0"과 같은 임의 값을 입력하지 마십시오. 대신 결측값을 데이터 집합의 기능에 대한 평균값 또는 중위값으로 바꾸는 것을 고려하십시오. 다른 형상의 값이 주어진 형상의 값을 예측하도록 모델을 교육할 수도 있습니다.

테스트 데이터에서 범주형 누락 기능이 예상되지만 네트워크가 누락 데이터 없이 데이터에 대해 학습된 경우, 네트워크는 누락 데이터를 무시하는 방법을 배우지 않습니다! 이 경우 누락된 항목이 있는 교육 샘플을 인위적으로 생성해야 합니다. 일부 교육 샘플을 여러 번 복사하고 테스트 데이터에서 누락될 것으로 예상되는 범주형 기능 중 일부를 삭제해야 합니다.

## 6.2.2 평가 프로토콜을 선택하세요.

이전 장에서 학습한 바와 같이 모델의 목적은 일반화를 달성하는 것이며, 모델 개발 프로세스 전반에 걸쳐 내리는 모든 모델링 결정은 일반화 성과를 측정하기 위한 검증 지표에 따라 결정됩니다. 검증 프로토콜의 목표는 실제 프로덕션 데이터에서 선택한 성공 지표(예: 정확도)를 정확하게 추정하는 것입니다. 그 과정의 신뢰성은 유용한 모델을 구축하는 데 매우 중요합니다.

5장에서는 세 가지 일반적인 평가 프로토콜을 검토했습니다.

- 홀드아웃 유효성 검사 세트 유지 - 데이터가 많을 때 수행할 수 있는 방법입니다.
- K-폴드 교차 검증 - 샘플 수가 너무 적어서 홀드아웃 검증을 신뢰할 수 없을 때 올바른 선택입니다.
- 반복 K-폴드 검증 수행 - 데이터가 거의 없을 때 매우 정확한 모델 평가를 수행합니다.

이것들 중에 하나만 골라주세요. 대부분의 경우 첫 번째 방법은 충분히 효과가 있을 것입니다. 앞에서 배웠듯이, 항상 검증 세트의 대표성에 유의하고 교육 세트와 검증 세트 사이에 중복 샘플이 없도록 주의하십시오.

## 6.2.3 기준선을 뛰어 넘으세요.

모형 자체에 대한 작업을 시작하면 5장에서 살펴본 것처럼 통계적 검정력을 달성하는 것이 초기 목표입니다. 즉, 간단한 기준선을 능가할 수 있는 작은 모형을 개발하는 것입니다.

이 단계에서 가장 중요한 세 가지 사항은 다음과 같습니다.

- 기능 엔지니어링—정보를 제공하지 않는 기능(기능 선택)을 걸러내고 문제에 대한 지식을 활용하여 유용한 새 기능을 개발할 수 있습니다.
- 올바른 아키텍처 이전 선택: 사용할 모델 아키텍처 유형은 무엇입니까? 촘촘하게 연결된 네트워크, 컨브넷, 반복적인 신경 네트워크, 트랜스포머 같은 거요? 딥러닝은 과제를 위한 좋은 접근법인가요, 아니면 다른 것을 사용해야 하나요?
- 충분한 교육 구성 선택—어떤 손실 기능을 사용해야 합니까? 배치 크기와 학습률은 어떻게 됩니까?

대부분의 문제에서 시작할 수 있는 기존 템플릿이 있습니다. 스팸 탐지기, 음악 추천 엔진 또는 이미지 분류기를 만든 첫 번째 사람은 아닙니다. 선행 기술을 조사하여 작업에서 가장 잘 수행할 수 있는 기능 엔지니어링 기술과 모델 아키텍처를 식별하십시오.

통계적인 힘을 얻는 것이 항상 가능한 것은 아닙니다. 합리적인 아키텍처를 여러 번 시도해도 단순한 기준선을 넘을 수 없다면 입력 데이터에 질문에 대한 답이 없는 것일 수 있습니다. 두 가지 가설을 세우고 있다는 것을 기억하십시오.
- 입력이 주어지면 출력을 예측할 수 있다는 가설을 세웁니다.
- 사용 가능한 데이터가 입력과 출력 간의 관계를 학습하는 데 충분한 정보를 제공한다는 가설을 세웁니다.

이러한 가설은 잘못된 것일 수 있으며, 이 경우 처음부터 다시 시작해야 합니다.

## 6.2.4 규모를 키우세요. : 과적합된 모델을 발전시키세요.

일단 통계적 힘을 가진 모델을 얻으면, 질문은 여러분의 모델이 충분히 강력하냐는 것입니다. 그것은 당면한 문제를 적절하게 모델링하기에 충분한 레이어와 파라미터를 가지고 있습니까? 

예를 들어, 로지스틱 회귀 분석 모형은 MNIST에 대한 통계적 검정력이 있지만 문제를 잘 해결하기에는 충분하지 않습니다. 머신러닝의 보편적인 장력은 최적화와 일반화 사이입니다. 이상적인 모델은 과소적합과 과적합, 과소용량과 과용량 사이의 경계에 서 있는 모델입니다. 이 경계선이 어디에 있는지 알아내려면 먼저 그 경계를 넘어야 합니다.

얼마나 큰 모형이 필요한지 파악하려면 지나치게 적합한 모형을 개발해야 합니다. 5장에서 학습한 바와 같이 이 작업은 매우 쉽습니다.

1. 층을 추가하세요
2. 층을 더 높게 만드세요
3. 더많은 에포크를 수행하세요

교육 손실 및 검증 손실은 물론 관심 있는 메트릭에 대한 교육 및 검증 값도 항상 모니터링합니다. 검증 데이터에 대한 모형의 성능이 저하되기 시작하면 과적합이 이루어진 것입니다.

## 6.2.5 모델을 정규화하고 조정하세요.

일단 통계적 능력을 갖추고 오버핏을 할 수 있게 되면, 여러분은 올바른 길을 가고 있다는 것을 알게 됩니다. 이 시점에서 목표는 일반화 성능을 최대화하는 것입니다.

이 단계에서는 모델이 최대한 양호해질 때까지 반복적으로 모델을 수정하고 교육하고 검증 데이터(현 시점에서 테스트 데이터가 아님)를 평가한 다음 다시 수정하고 반복합니다. 다음과 같은 몇 가지 방법을 시도해 보십시오.

- 다른 아키텍처를 시도하고 층을 추가하거나 제거하세요.
- 드롭아웃을 추가하세요
- 모형이 작으면 L1 또는 L2 정규화를 추가하세요.
- 최적의 구성을 찾기 위해 다양한 하이퍼 파라미터(예: 계층당 단위 수 또는 최적화 프로그램의 학습 속도)를 사용해 보십시오.
- 선택적으로, 데이터 큐레이션 또는 피쳐 엔지니어링을 반복할 수 있습니다. 즉, 더 많은 데이터를 수집하고 주석을 달거나, 더 나은 피쳐를 개발하거나, 유용한 것으로 보이지 않는 피쳐를 제거할 수 있습니다.

케라스와 같은 자동화된 하이퍼 파라미터 튜닝 소프트웨어를 사용하면 이 작업의 상당 부분을 자동화할 수 있습니다.튜너. 13장에서 다루도록 하겠습니다.

검증 프로세스의 피드백을 사용하여 모형을 조정할 때마다 검증 프로세스에 대한 정보가 모형에 유출됩니다. 몇 번만 반복해도 무해하지만, 여러 반복에 걸쳐 체계적으로 수행되면 검증 데이터에 대해 직접 교육을 받은 모델이 없음에도 불구하고 결국 검증 프로세스에 모델이 과도하게 적합하게 됩니다. 이것은 평가 과정의 신뢰성을 떨어뜨립니다.

만족스러운 모델 구성을 개발했으면 사용 가능한 모든 데이터(교육 및 검증)에 대해 최종 생산 모델을 교육하고 테스트 세트에서 마지막으로 평가할 수 있습니다. 검정 세트의 성능이 검증 데이터에서 측정된 성능보다 훨씬 나쁜 것으로 판명되면 이는 검증 절차를 신뢰할 수 없거나 모형의 매개 변수를 조정하는 동안 검증 데이터에 과적합하기 시작했음을 의미할 수 있습니다. 이 경우 K-폴드 반복 유효성 검사와 같은 보다 안정적인 평가 프로토콜로 전환할 수 있습니다.

#6.3 당신의 모델을 배포하세요.

당신의 모델은 테스트 세트에 대한 최종 평가를 성공적으로 마쳤습니다. 이제 배치하고 생산적인 삶을 시작할 준비가 되었습니다.

## 6.3.1 당신의 작품을 관계자들에게 설명하고 기대감을 주세요.

성공과 고객 신뢰는 지속적으로 고객의 기대에 부응하거나 그 이상을 달성하는 것입니다. 실제로 제공하는 시스템은 그 그림의 절반에 불과합니다. 나머지 절반은 출시 전에 적절한 기대치를 설정하고 있습니다.

AI 시스템에 대한 비전문가들의 기대는 종종 비현실적입니다. 예를 들어, 시스템이 작업을 "이해"하고 작업 맥락에서 인간과 유사한 상식을 행사할 수 있다고 기대할 수 있습니다. 이 문제를 해결하려면 잘못 분류된 표본, 특히 잘못 분류된 표본이 놀라울 수 있는 표본의 모습을 보여주는 등 모형의 고장 모드의 몇 가지 예를 보여 주는 것을 고려해야 합니다.

특히 이전에 사람이 처리했던 프로세스의 경우 인간 수준의 성능을 기대할 수도 있습니다. 대부분의 머신러닝 모델은 인간이 만든 레이블에 근접하도록 (불완전하게) 훈련되었기 때문에 거의 도달하지 못합니다. 모델 성능 기대치를 명확히 전달해야 합니다. "모델은 98%의 정확도를 가지고 있다"(대부분의 사람들이 정신적으로 최대 100%까지 반올림한다)와 같은 추상적인 문장을 사용하는 것을 피하고, 예를 들어, 잘못된 부정 비율과 잘못된 긍정 비율에 대해 이야기하는 것을 선호합니다. "이러한 설정을 사용하면 부정 행위 탐지 모델의 경우 부정 행위 탐지율이 5%이고 부정 행위 탐지율이 2.5%입니다. 매일 평균 200개의 유효한 트랜잭션에 사기 플래그가 표시되어 수동 검토를 위해 보내지고 평균 14개의 사기 트랜잭션이 누락됩니다. 평균 266건의 부정 거래가 정확하게 적발될 것입니다." 모델의 성능 측정 기준을 비즈니스 목표와 명확하게 연관시킵니다.

또한 트랜잭션에 플래그를 지정해야 하는 확률 임계값(임계값이 다르면 잘못된 부정 비율과 잘못된 긍정 비율이 다름)과 같은 주요 시작 매개 변수 선택에 대해서도 이해 관계자와 논의해야 합니다. 이러한 결정에는 비즈니스 컨텍스트를 깊이 이해해야만 처리할 수 있는 트레이드오프가 포함됩니다.

## 6.3.2 추론 모델을 보내세요.

머신러닝 프로젝트는 훈련된 모델을 저장할 수 있는 코랩 노트북에 도착해도 끝나지 않습니다. 교육 중에 조작한 것과 동일한 파이썬 모델 개체를 프로덕션으로 넣는 경우는 거의 없습니다.

첫째, 파이썬이 아닌 다른 곳으로 모델을 내보내는 것이 좋습니다.
- 운영 환경에서 파이썬을 전혀 지원하지 않을 수 있습니다. 예를 들어, 파이썬이 모바일 앱 또는 임베디드 시스템인 경우입니다.
- 나머지 앱이 Python이 아닌 경우(JavaScript, C++ 등) 모델을 서비스하기 위해 Python을 사용하면 상당한 오버헤드가 발생할 수 있습니다.

둘째, 생산 모델은 교육용이 아니라 예측(추론이라는 단계) 출력에만 사용되므로 모델을 더 빠르게 만들고 메모리 공간을 줄일 수 있는 다양한 최적화를 수행할 수 있습니다.

이제 사용 가능한 다양한 모델 배포 옵션을 간단히 살펴보겠습니다.

### REST API로 모델을 배포하기.

이 방법은 모델을 제품으로 변환하는 일반적인 방법일 수 있습니다. 서버 또는 클라우드 인스턴스에 TensorFlow를 설치하고 REST API를 통해 모델의 예측을 쿼리합니다. 플라스크(또는 다른 Python 웹 개발 라이브러리)와 같은 것을 사용하여 자신만의 서빙 앱을 구축하거나 TensorFlow의 라이브러리를 사용하여 모델을 API로 제공할 수 있습니다(TensorFlow 서빙이라고 합니다. TensorFlow 서빙(www.tensorflow.org/tfx/guide/serving)을 사용하여 Keras 모델을 몇 분 안에 배포할 수 있습니다.

다음과 같은 경우 이 배포 설정을 사용해야 합니다.
- 모델의 예측을 사용할 애플리케이션은 인터넷에 안정적으로 액세스할 수 있습니다. 예를 들어 응용 프로그램이 모바일 응용 프로그램인 경우 원격 API에서 예측 정보를 제공하면 비행기 모드나 저연결 환경에서 응용 프로그램을 사용할 수 없습니다.
- 응용 프로그램에는 엄격한 대기 시간 요구사항이 없습니다. 요청, 추론 및 응답 왕복에는 일반적으로 약 500ms가 소요됩니다.
- 추론을 위해 전송된 입력 데이터는 그다지 민감하지 않습니다. 즉, 데이터는 모델이 확인해야 하므로 해독된 형식으로 서버에서 사용할 수 있어야 합니다(그러나 HTTP 요청 및 응답에는 SSL 암호화를 사용해야 **함**).

예를 들어 이미지 검색 엔진 프로젝트, 음악 추천 시스템, 신용 카드 사기 탐지 프로젝트, 위성 이미지 프로젝트는 모두 REST API를 통해 서비스하기에 적합합니다.

모델을 REST API로 배포할 때 중요한 질문은 코드를 직접 호스팅할지 아니면 완전히 관리되는 타사 클라우드 서비스를 사용할지 여부입니다. 예를 들어 구글 제품인 Cloud AI Platform을 사용하면 TensorFlow 모델을 Google Cloud Storage(GCS)에 업로드하고 API endpoint를 통해 쿼리할 수 있습니다. 일괄 처리 예측, 로드 밸런싱 및 확장과 같은 많은 실제적인 세부 사항을 처리합니다.

### 장치에서 모델을 배포합니다.

스마트폰, 로봇의 내장형 ARM CPU 또는 작은 장치의 마이크로컨트롤러 등 해당 애플리케이션을 실행하는 동일한 장치에 모델을 사용해야 하는 경우가 있습니다. 예를 들어, 여러분이 지목한 장면에서 사람과 얼굴을 자동으로 감지할 수 있는 카메라를 이미 본 적이 있을 것입니다. 그것은 아마도 카메라에서 직접 실행되는 작은 딥러닝 모델이었을 것입니다.

다음과 같은 경우 이 설정을 사용해야 합니다.

- 모델에 엄격한 지연 시간 제약이 있거나 연결성이 낮은 환경에서 실행해야 합니다. 몰입형 증강 현실 애플리케이션을 구축하는 경우 원격 서버를 쿼리하는 것은 실행 가능한 옵션이 아닙니다.
- 모델을 대상 장치의 메모리 및 전력 제약 조건에서 실행할 수 있도록 충분히 작게 만들 수 있습니다(TensorFlow Model Optimization Toolkit:[10]을 사용하면 도움이 됩니다).
- 런타임 효율성과 정확성 사이에는 항상 절충이 있기 때문에 메모리 및 전력 제약으로 인해 대형 GPU에서 실행할 수 있는 최상의 모델만큼 좋지 않은 모델을 제공해야 하는 경우가 많습니다.
- 입력 데이터는 엄격하게 중요하므로 원격 서버에서 암호를 해독할 수 없습니다.


예를 들어, 스팸 탐지 모델은 채팅 앱의 일부로 최종 사용자의 스마트폰에서 실행되어야 합니다. 왜냐하면 메시지는 종단 간 암호화되므로 원격으로 호스팅된 모델에서 전혀 읽을 수 없기 때문입니다. 마찬가지로 불량 쿠키 탐지 모델도 엄격한 지연 시간 제약이 있어 공장에서 실행해야 합니다. 다행히 이 경우 전력이나 공간 제약이 없으므로 GPU에서 실제로 모델을 실행할 수 있습니다.


Keras 모델을 스마트폰 또는 임베디드 장치에 배포하려면 TensorFlow Lite(www.tensorflow.org/lite)를 사용해야 합니다. Android 및 iOS 스마트폰뿐만 아니라 ARM64 기반 컴퓨터, Lasberry Pi 또는 특정 마이크로컨트롤러에서 실행되는 효율적인 장치 딥러닝 추론을 위한 프레임워크입니다. Keras 모델을 TensorFlow Lite 형식으로 쉽게 전환할 수 있는 변환기가 포함되어 있습니다.


### 브라우저에서 모델을 배포하세요.

딥 러닝은 브라우저 기반 또는 데스크톱 기반 JavaScript 응용프로그램에서 자주 사용됩니다. 일반적으로 애플리케이션이 REST API를 통해 원격 모델을 쿼리할 수 있지만, 대신 브라우저의 사용자 컴퓨터에서 직접 모델을 실행하도록 하면 주요 이점을 얻을 수 있습니다(사용 가능한 경우 GPU 리소스를 활용).


다음과 같은 경우에 이 설정을 사용합니다.

- 컴퓨팅을 최종 사용자에게 오프로드하여 서버 비용을 크게 절감할 수 있습니다.
- 입력 데이터는 최종 사용자의 컴퓨터 또는 전화기에 남아 있어야 합니다. 예를 들어, 스팸 탐지 프로젝트에서 채팅 앱의 웹 버전과 데스크톱 버전(JavaScript로 작성된 크로스 플랫폼 앱으로 구현됨)은 로컬에서 실행되는 모델을 사용해야 합니다.
- 애플리케이션에는 엄격한 지연 시간 제약이 있습니다. 최종 사용자의 노트북이나 스마트폰에서 실행되는 모델은 서버의 대형 GPU에서 실행되는 모델보다 속도가 느릴 수 있지만, 추가 100ms의 네트워크 왕복 운행 시간은 없습니다.
- 모델이 다운로드되고 캐시된 후에도 연결 없이 계속 작동하려면 앱이 필요합니다.


물론 모델이 사용자의 노트북이나 스마트폰의 CPU, GPU 또는 RAM을 독점하지 않을 정도로 작은 경우에만 이 옵션을 사용해야 합니다. 또한 전체 모델이 사용자의 장치에 다운로드되므로 모델에 대해 비밀로 유지할 필요가 없도록 해야 합니다. 훈련된 딥러닝 모델이 주어지면 일반적으로 교육 데이터에 대한 일부 정보를 복구할 수 있습니다. 중요한 데이터에 대해 훈련된 모델을 공개하지 않는 것이 좋습니다.


JavaScript에서 모델을 배포하기 위해 TensorFlow 에코시스템에는 TensorFlow.js(www.tensorflow.org/js),는 거의 모든 Keras API(원래 WebKeras라는 작업 이름으로 개발됨)와 많은 하위 레벨 TensorFlow API를 구현하는 딥러닝용 JavaScript 라이브러리입니다. 저장된 Keras 모델을 TensorFlow.js로 쉽게 가져와 브라우저 기반 JavaScript 앱 또는 데스크톱 Electronic 앱의 일부로 쿼리할 수 있습니다.


### 추론 모형 최적화를 하세요.

사용 가능한 전력 및 메모리(스마트폰 및 임베디드 장치)에 엄격한 제약이 있는 환경이나 대기 시간이 짧은 애플리케이션에 배포할 때 추론할 수 있도록 모델을 최적화하는 것이 특히 중요합니다. TensorFlow.js로 가져오거나 TensorFlow Lite로 내보내기 전에 항상 모델을 최적화해야 합니다.


적용할 수 있는 두 가지 일반적인 최적화 기법이 있습니다.

- 가중치 가지치기: 가중치 텐서의 모든 계수가 예측에 동일하게 기여하는 것은 아닙니다. 가장 유의한 항목만 유지하면 모형의 계층에서 모수의 수를 크게 줄일 수 있습니다. 따라서 성능 메트릭에서 적은 비용으로 모델의 메모리 및 컴퓨팅 설치 공간을 줄일 수 있습니다. 적용할 가지치기 양을 조정하면 크기와 정확도 사이의 균형을 조정할 수 있습니다.

- 가중치 정량화: 딥 러닝 모델은 단일 정밀 부동소수점(플로트32) 가중치를 사용하여 훈련됩니다. 그러나 가중치를 8비트 부호 정수(int8)로 정량화하면 4배 작지만 원래 모델의 정확도에 가까운 추론 전용 모델을 얻을 수 있습니다.

TensorFlow 에코시스템에는 Keras API와 긴밀하게 통합된 가중치 정리 및 정량화 툴킷(www.tensorflow.org/model_optimization)이 포함됩니다.


## 6.3.3 너의 모델을 계속해서 모니터링 하세요.

추론 모델을 내보내고 이를 애플리케이션에 통합한 후 프로덕션 데이터에 대해 모의 실행을 수행했습니다. 이 모델은 예상대로 작동합니다. 유닛 테스트와 로깅 및 상태 모니터링 코드를 작성했습니다. 완벽합니다. 이제 큰 빨간색 버튼을 눌러 실운영에 투입할 차례입니다.


심지어 이것이 끝이 아닙니다. 모델을 구축한 후에는 모델의 동작, 새 데이터에 대한 성능, 나머지 애플리케이션과의 상호 작용 및 궁극적으로 비즈니스 메트릭에 미치는 영향을 계속 모니터링해야 합니다.

- 새로운 음악 추천 시스템을 구축한 후 온라인 라디오에 대한 사용자 참여가 상향식입니까, 아니면 하향식입니까? 새로운 클릭률 예측 모델로 전환한 후 평균 광고 클릭률이 증가했습니까? 랜덤 A/B 검정을 사용하여 모형 자체의 영향을 다른 변경 사항과 분리하는 것을 고려하십시오. 사례의 일부는 새 모형을 통과해야 하고 다른 관리 부분 집합은 이전 공정을 고수해야 합니다. 충분히 많은 사례가 처리되고 나면, 두 사례의 결과 차이는 모델에 기인할 가능성이 높습니다.

- 가능하면 생산 데이터에 대한 모델의 예측에 대해 정기적인 수동 감사를 실시하십시오. 일반적으로 데이터 주석과 동일한 인프라를 재사용할 수 있습니다. 생산 데이터의 일부를 수동으로 주석을 달도록 전송하고 모델의 예측값을 새 주석과 비교합니다. 예를 들어 이미지 검색 엔진 및 잘못된 쿠키 플래그 지정 시스템에 대해 이 작업을 수행해야 합니다.

- 수동 감사가 불가능한 경우, 사용자 설문 조사와 같은 대체 평가 방법(예: 스팸 및 유해 콘텐츠 플래그 지정 시스템의 경우)을 고려하십시오.


## 6.3.4 너의 모델을 계속해서 유지관리 하세요.

마지막으로, 영원한 모델은 없습니다. 컨셉 드리프트에 대해 이미 배웠습니다. 시간이 지남에 따라 생산 데이터의 특성이 변화하여 모델의 성능과 관련성이 점차 저하됩니다. 음악 추천 시스템의 수명이 몇 주 내로 계산됩니다. 신용카드 사기 탐지 시스템은 며칠이 걸릴 것입니다. 이미지 검색 엔진을 위한 최고의 경우 2년입니다.


모델이 출시되자마자 모델을 대체할 다음 세대를 교육할 준비를 해야 합니다. 다음과 같이 하십시오.

- 생산 데이터의 변화를 주의하세요. 새로운 기능을 사용할 수 있습니까? 레이블 세트를 확장해야 합니까 아니면 편집해야 합니까?

- 데이터를 계속 수집하고 주석을 달 수 있으며, 시간이 지남에 따라 주석 파이프라인을 계속 개선할 수 있습니다. 특히 현재 모형에 대해 분류하기 어려운 표본을 수집하는 데 특히 주의해야 합니다. 이러한 표본은 성능을 향상시키는 데 도움이 될 가능성이 높습니다.


이것으로 머신러닝의 보편적인 워크플로우가 마무리되었습니다. 이 점에 유의해야 할 사항이 많습니다. 전문가가 되기 위해서는 시간과 경험이 필요하지만 걱정하지 마세요, 여러분은 이미 몇 장 전보다 훨씬 더 현명해졌습니다. 이제 머신러닝 프로젝트의 전체 스펙트럼이라는 큰 그림에 익숙해졌습니다. 이 책의 대부분은 모델 개발 부분에 중점을 두지만, 이제 전체 워크플로우의 일부분에 불과하다는 것을 알게 되었습니다. 항상 큰 그림을 명심하세요!


# 6.4 6장 요약

* 당신이 새로운 머신러닝 프로젝트를 맡았을 때 첫번째로 해야할 일은 목전에 그 문제를 정의내려야 합니다.
  + 당신이 수행하려는 것의 맥락을 더 넓게 이해하세요. - 마지막 목표가 무엇이고 어떠한 제약이 있는지에 대해.
  + 데이터셋을 모으고 주석을 달으세요 그렇게 하면 당신의 데이터에 대해 깊게 이해 할 것이라는 것을 확신합니다.
  + 당신의 문제에 대해 어떻게 당신이 성공을 가늠할 것인지 선택하세요.

 * 일단 당신이 그 문제를 이해하고 적절한 데이터셋을 가진다면 모델을 개발하세요.
  + 당신의 데이터를 준비하세요.
  + 당신의 평가 프로토콜을 선택하세요 : hold-out검증? K겹 검증? 당신은 어떤 데이터의 몫을 검증을 위해 사용 할 것인가요?
  + 검정력을 달성하세요. : 간단한 기준선을 뛰어 넘어라.
  + 규모를 키우세요. : 모델이 과적합이 되도록 만드세요.
  + 당신의 모델을 규칙화하고 검증데이터에서의 성과를 기본으로 한 하이퍼 파라미터를 조정하세요. 많은 양의 머신들은 오로지 이 단계에 집중하는 경향이 있습니다. 그러나 마음속에 큰 그림을 그려야 합니다.

 * 당신의 모델이 준비가 되었고 테스트 셋에서 좋은 성과를 낸다면, 그 모델을 배포할 준비가 되었습니다.
  + 첫째, 관계자들과 함께 적절한 기대치를 거는 것에 대해 확신하세요.
  + 추론을 위한 최종 모델을 최적화하세요, 그리고 여러가지 배포할 수 있는 환경에 그 모델을 올리세요. - 웹 서버, 모바일, 브라우저, 내장 디바이스 등등...
  + 올린 모델의 성과를 계속 지켜보세요. 그리고 계속해서 데이터를 수집하세요 그렇게 되면 당신은 그 다음 세대 모델을 개발할 수 있습니다.
